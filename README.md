# ğŸµ FMA Genre Classification (CNN + Mel-Spectrograms)

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)
![License](https://img.shields.io/badge/License-MIT-green)

Ce projet implÃ©mente un pipeline complet de **Deep Learning** pour la classification de genres musicaux Ã  partir du dataset **FMA-small** (8 genres, 8 000 pistes, extraits de 30s).

Deux pipelines sont fournis : une **baseline** sur Mel-spectrogrammes bruts et une **version augmentÃ©e** avec Data Augmentation (TimeStretch, PitchShift, bruit, etc.) optimisÃ©e pour **Apple Silicon (M1/M2/M3)** via le backend `MPS` de PyTorch.

---

## ğŸ“‚ Structure du projet

```bash
FMA_CNN_AL/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Fichiers .mp3 (non versionnÃ©s)
â”‚   â””â”€â”€ metadata/            # tracks.csv
â”‚
â”œâ”€â”€ mels/                    # Spectrogrammes de base (.npy, ignorÃ©s par git)
â”œâ”€â”€ mels_augmented/          # Spectrogrammes augmentÃ©s (.npy, ignorÃ©s par git)
â”‚
â”œâ”€â”€ src/                     # ğŸŸ¢ CODE BASELINE
â”‚   â”œâ”€â”€ preprocess.py        # MP3 -> Mel-spectrogrammes
â”‚   â”œâ”€â”€ dataset.py           # Dataset PyTorch (baseline)
â”‚   â”œâ”€â”€ model.py             # CNN lÃ©ger (baseline)
â”‚   â”œâ”€â”€ train.py             # EntraÃ®nement baseline
â”‚   â””â”€â”€ visualize.py         # Courbes & comparaisons
â”‚   â””â”€â”€ analyze.py           # Analyse & Ã©valuation des modÃ¨les
â”‚
â”œâ”€â”€ src_aug/                 # ğŸŸ  CODE AUGMENTÃ‰ (Data Augmentation)
â”‚   â”œâ”€â”€ preprocess.py        # GÃ©nÃ©ration mels + versions augmentÃ©es
â”‚   â”œâ”€â”€ dataset.py           # Dataset gÃ©rant les fichiers augmentÃ©s
â”‚   â”œâ”€â”€ model.py             # CNN ajustÃ© / rÃ©gularisÃ©
â”‚   â””â”€â”€ train.py             # EntraÃ®nement sur donnÃ©es augmentÃ©es
â”‚   â””â”€â”€ analyze.py           # Analyse & Ã©valuation (augmentÃ©)
â”‚
â”œâ”€â”€ results/                 # MÃ©triques & graphiques
â”‚   â”œâ”€â”€ comparison_curves.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ final_metrics.txt
â”‚   â””â”€â”€ *.npy                # Historiques de loss (ignorÃ©s par git)
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Installation

### 2.1. PrÃ©requis

- Python â‰¥ 3.10  
- `git` et un environnement virtuel (recommandÃ©, ex. `venv` ou `conda`).

Cloner le dÃ©pÃ´t puis installer les dÃ©pendances :

```bash
git clone https://github.com/leducantoine/FMA_CNN_AL.git
cd FMA_CNN_AL

# Optionnel mais recommandÃ©
python -m venv .venv
source .venv/bin/activate  # sous macOS / Linux
# .venv\Scripts\activate   # sous Windows PowerShell

pip install -r requirements.txt
```

### 2.2. AccÃ©lÃ©ration Apple Silicon (MPS)

Le code dÃ©tecte automatiquement la prÃ©sence de MPS (`device = "mps"`), sinon il bascule sur CPU.
VÃ©rifier que PyTorch voit bien MPS :

```bash
python -c "import torch; print(f'MPS Available: {torch.backends.mps.is_available()}')"
```

---

## ğŸ’¾ PrÃ©paration du dataset (FMA-Small)

Le dataset **FMA-small** n'est pas versionnÃ© dans le dÃ©pÃ´t.

1. TÃ©lÃ©charger le dataset depuis Kaggle (ex. FMA-small dÃ©rivÃ© de `fma` original) :  
   https://www.kaggle.com/datasets/aaronyim/fma-small
2. Extraire les fichiers et organiser comme suit :

```bash
data/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ 000/             # Fichiers .mp3
â”‚   â”œâ”€â”€ 001/             # Fichiers .mp3
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ 155/             # Fichiers .mp3
â””â”€â”€ metadata/
    â””â”€â”€ tracks.csv    # Fichier de mÃ©tadonnÃ©es FMA---

## âš™ï¸ Utilisation pas Ã  pas

Cette section explique exactement quoi lancer et dans quel ordre.

### Ã‰tape A â€“ Baseline (rapide)

**1. PrÃ©-calcul des Mel-spectrogrammes** (une seule fois) :

```bash
python src/preprocess.py
```

- Lit les `.mp3` dans `data/raw/` (dossiers 000/ Ã  155/).- Sauvegarde un `.npy` par piste dans `mels/`.

**2. EntraÃ®nement du modÃ¨le baseline** :
- Lit les `.mp3` dans `data/raw/` (dossiers 000/ Ã  155/).

Ce script :
- Charge les spectrogrammes depuis `mels/`.  
- Effectue le split train/validation/test.  
- EntraÃ®ne un CNN lÃ©ger sur `mps` (si dispo) ou CPU.  
- Sauvegarde les courbes / mÃ©triques dans `results/`  
  (par ex. loss / accuracy, `final_metrics.txt`, etc.).

### Ã‰tape B â€“ Pipeline augmentÃ© (performant)

**1. GÃ©nÃ©ration des Mel-spectrogrammes augmentÃ©s** :

```bash
python src_aug/preprocess.py
```

- CrÃ©e plusieurs versions par piste (Original + Noise + TimeStretch/PitchShift).
- Stocke les spectrogrammes dans `mels_augmented/`.

**2. EntraÃ®nement sur donnÃ©es augmentÃ©es** :

```bash
python src_aug/train.py
```

Ce script :
- Charge `mels_augmented/`.  
- EntraÃ®ne un modÃ¨le lÃ©gÃ¨rement modifiÃ© (CNN avec ajustements / rÃ©gularisation).  
- Sauvegarde les mÃ©triques et courbes dans `results/`  
  (y compris les donnÃ©es nÃ©cessaires pour la comparaison baseline vs augmentÃ©).

### Ã‰tape C â€“ Ã‰valuation & comparaison des modÃ¨les
Une fois les deux entraÃ®nements effectuÃ©s (baseline + augmentÃ©) :

**Option 1 : Ã‰valuation complÃ¨te avec `analyze.py`** (recommandÃ©) :

```bash
# Pour baseline
python src/analyze.py

# Pour version augmentÃ©e
python src_aug/analyze.py
```

Ce script :
- Charge les modÃ¨les entraÃ®nÃ©s depuis `results/`.
- Ã‰value sur le test set avec mÃ©triques dÃ©taillÃ©es (accuracy, F1, confusion matrix).
- Sauvegarde les rÃ©sultats dans `results/`.

**Option 2 : Comparaison visuelle simple avec `visualize.py`** :

```bash
python src/visualize.py
```

- Charge les historiques de loss/accuracy stockÃ©s en `.npy`.
- GÃ©nÃ¨re les figures de comparaison dans `results/`  
  (par ex. `comparison_curves.png`, `confusion_matrix.png`).

---

## ğŸ“Š RÃ©sultats & architecture

- Les fichiers principaux produits sont :  
  - `results/comparison_curves.png` : Ã©volution des mÃ©triques baseline vs augmentÃ©.
  - `results/confusion_matrix.png` : matrice de confusion du meilleur modÃ¨le.  

- Le modÃ¨le est un **CNN lÃ©ger** composÃ© de 4 blocs Convolution â†’ BatchNorm â†’ ReLU â†’ MaxPool, suivi d'un flatten et d'une couche linÃ©aire finale vers 8 genres.

---

## ğŸ›  Notes techniques & extension

- Les spectrogrammes sont calculÃ©s **offline** pour accÃ©lÃ©rer l'entraÃ®nement et limiter la charge CPU.
- Le backend `MPS` est utilisÃ© automatiquement sur Mac M1/M2/M3 s'il est disponible, sinon bascule sur CPU.

Pistes d'extension possibles :  
- Ajouter davantage de data augmentation (SpecAugment, mixup).  
- Tester des architectures plus profondes (CRNN, attention).  
- IntÃ©grer un scheduler, de l'early stopping ou du logging avancÃ© (Weights & Biases, TensorBoard).

---

## ğŸ“ Licence & auteur

- Licence : **MIT**  
- Auteur : **Antoine Leduc**  

Projet rÃ©alisÃ© dans le cadre d'une Ã©tude sur l'efficacitÃ© de CNN lÃ©gers pour la classification de genres musicaux sur architectures ARM/Apple Silicon.
