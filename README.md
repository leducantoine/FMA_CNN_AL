# üéµ FMA Genre Classification (CNN + Mel-Spectrograms)

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)
![License](https://img.shields.io/badge/License-CentraleSup%C3%A9lec-blue)

This project implements a complete **Deep Learning** pipeline for music genre classification using the **FMA-small** dataset (8 genres, 8,000 tracks, 30s excerpts).

Two pipelines are provided: a **baseline** on raw Mel-spectrograms and an **augmented version** with Data Augmentation (TimeStretch, PitchShift, Noise, etc.) optimized for **Apple Silicon (M1/M2/M3)** via PyTorch's `MPS` backend.

---

## üìÇ Project Structure

```bash
FMA_CNN_AL/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                 # .mp3 files (not versioned)
‚îÇ   ‚îî‚îÄ‚îÄ metadata/            # tracks.csv
‚îÇ
‚îú‚îÄ‚îÄ mels/                    # Baseline spectrograms (.npy, git-ignored)
‚îú‚îÄ‚îÄ mels_augmented/          # Augmented spectrograms (.npy, git-ignored)
‚îÇ
‚îú‚îÄ‚îÄ src/                     # üü¢ BASELINE CODE
‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py        # MP3 -> Mel-spectrograms
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py           # PyTorch Dataset (baseline)
‚îÇ   ‚îú‚îÄ‚îÄ model.py             # Lightweight CNN (baseline)
‚îÇ   ‚îú‚îÄ‚îÄ train.py             # Baseline training
‚îÇ   ‚îú‚îÄ‚îÄ visualize.py         # Curves & comparisons
‚îÇ   ‚îî‚îÄ‚îÄ analyze.py           # Model analysis & evaluation
‚îÇ
‚îú‚îÄ‚îÄ src_aug/                 # üü† AUGMENTED CODE (Data Augmentation)
‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py        # Mel generation + augmented versions
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py           # Dataset handling augmented files
‚îÇ   ‚îú‚îÄ‚îÄ model.py             # Adjusted / regularized CNN
‚îÇ   ‚îú‚îÄ‚îÄ train.py             # Training on augmented data
‚îÇ   ‚îî‚îÄ‚îÄ analyze.py           # Analysis & evaluation (augmented)
‚îÇ
‚îú‚îÄ‚îÄ results/                 # Metrics & graphics
‚îÇ   ‚îú‚îÄ‚îÄ comparison_curves.png
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png
‚îÇ   ‚îú‚îÄ‚îÄ final_metrics.txt
‚îÇ   ‚îî‚îÄ‚îÄ *.npy                # Loss histories (git-ignored)
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## üöÄ Installation

### 2.1. Prerequisites

- Python ‚â• 3.10  
- `git` and a virtual environment (recommended, e.g. `venv` or `conda`).

Clone the repository and install dependencies:

```bash
git clone https://github.com/leducantoine/FMA_CNN_AL.git
cd FMA_CNN_AL

# Optional but recommended
python -m venv .venv
source .venv/bin/activate  # on macOS / Linux
# .venv\\Scripts\\activate   # on Windows PowerShell

pip install -r requirements.txt
```

### 2.2. Apple Silicon (MPS) Acceleration

The code automatically detects MPS (`device = "mps"`), otherwise falls back to CPU.
Verify that PyTorch sees MPS:

```bash
python -c "import torch; print(f'MPS Available: {torch.backends.mps.is_available()}')"
```

---

## üíæ Dataset Preparation (FMA-Small)

The **FMA-small** dataset is not versioned in this repository.

1. Download the dataset from Kaggle (e.g. FMA-small derived from original `fma`):  
   https://www.kaggle.com/datasets/aaronyim/fma-small
2. Extract files and organize as follows:

```bash
data/
‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ 000/             # .mp3 files
‚îÇ   ‚îú‚îÄ‚îÄ 001/             # .mp3 files
‚îÇ   ‚îú‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ 155/             # .mp3 files
‚îî‚îÄ‚îÄ metadata/
    ‚îî‚îÄ‚îÄ tracks.csv    # FMA metadata file
```

> **Important**: The `data/raw/` folder should not be versioned on GitHub (see `.gitignore`).

---

## ‚öôÔ∏è Step-by-Step Usage

This section explains exactly what to run and in which order.

### Step A ‚Äì Baseline (fast)

**1. Pre-compute Mel-spectrograms** (once):

```bash
python src/preprocess.py
```

- Reads `.mp3` files from `data/raw/` (folders 000/ to 155/).
- Saves one `.npy` file per track in `mels/`.

**2. Train the baseline model**:

```bash
python src/train.py
```

This script:
- Loads spectrograms from `mels/`.  
- Performs train/validation/test split.  
- Trains a lightweight CNN on `mps` (if available) or CPU.  
- Saves curves / metrics in `results/`  
  (e.g. loss / accuracy, `final_metrics.txt`, etc.).

### Step B ‚Äì Augmented pipeline (better performance)

**1. Generate augmented Mel-spectrograms**:

```bash
python src_aug/preprocess.py
```

- Creates multiple versions per track (Original + Noise + TimeStretch/PitchShift).
- Stores spectrograms in `mels_augmented/`.

**2. Train on augmented data**:

```bash
python src_aug/train.py
```

This script:
- Loads `mels_augmented/`.  
- Trains a slightly modified model (CNN with adjustments / regularization).  
- Saves metrics and curves in `results/`  
  (including data needed for baseline vs augmented comparison).

### Step C ‚Äì Evaluation & model comparison

Once both trainings are completed (baseline + augmented):

**Option 1: Complete evaluation with `analyze.py`** (recommended):

```bash
# For baseline
python src/analyze.py

# For augmented version
python src_aug/analyze.py
```

This script:
- Loads trained models from `results/`.
- Evaluates on test set with detailed metrics (accuracy, F1, confusion matrix).
- Saves results in `results/`.

**Option 2: Simple visual comparison with `visualize.py`**:

```bash
python src/visualize.py
```

- Loads loss/accuracy histories stored in `.npy`.
- Generates comparison figures in `results/`  
  (e.g. `comparison_curves.png`, `confusion_matrix.png`).

---

## üìä Results & Architecture

- Main output files:  
  - `results/comparison_curves.png`: metric evolution baseline vs augmented.
  - `results/confusion_matrix.png`: confusion matrix of the best model.  

- The model is a **lightweight CNN** composed of 4 blocks Convolution ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool, followed by flatten and a final linear layer to 8 genres.

---

## üõ† Technical Notes & Extensions

- Spectrograms are computed **offline** to speed up training and limit CPU load.
- The `MPS` backend is used automatically on Mac M1/M2/M3 if available, otherwise falls back to CPU.

Possible extension paths:  
- Add more data augmentation (SpecAugment, mixup).  
- Test deeper architectures (CRNN, attention).  
- Integrate scheduler, early stopping, or advanced logging (Weights & Biases, TensorBoard).

---

## üìù License & Author

- License: **CentraleSup√©lec Academic Project**-
- Author: **Antoine Leduc**

Project conducted as a study on the effectiveness of lightweight CNNs for music genre classification on ARM/Apple Silicon architectures.
